# 1. 信息熵

本文 的 log2 缩写为log

信息熵描述信息源各可能事件发生的不确定性。

举例: 

​		 一枚硬币有两种等可能事件, 1/2

​		  因此 log 2 = 1 只需要1个比特位进行通信即可传输

​		 一个骰子有6种等可能事件 1/6

​		 因此 log6 ＝2.57 因此需要3个比特位进行传输



如果硬币不均匀的话  正面是 0.2 反面是 0.8的概率

这个时候 0.2 可以简化为 在 1/0.2 个球中摸出一个球的概率  也就是5种等可能事件

​                 0.5 可以简化为 在 1/0.8 个球中摸出一个球的概率  即1.25种等可能事件



因此他们的信息量为 log5 与 log1.25

再乘上各自的概率 总的期望概率为 0.2*log5+0.8\*log1.25

因此香农的公式为 ∑ p log 1/p 即    -∑P(xi)log(2,P(xi)) (i=1,2,..n)

求出来的值也被称为 信息熵